{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "     \n",
    "def alphanum_key(s):\n",
    "    ''' \n",
    "    Turn a string into a list of string and number chunks.\n",
    "    E.g. \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    '''\n",
    "    return [tryint(c) for c in re.split('([0-9]+)', s)]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    ''' \n",
    "    Sort the given list in the way that humans expect.\n",
    "    '''\n",
    "    l.sort(key=alphanum_key)\n",
    "    \n",
    "def plot_images(data, layout='row', cols=2, figsize=(20, 12)):\n",
    "    '''\n",
    "    Utility function for plotting images\n",
    "    :param data [(ndarray, string)]: List of data to display, [(image, title)]\n",
    "    :param layout (string): Layout, row-wise or column-wise\n",
    "    :param cols (number): Number of columns per row\n",
    "    :param figsize (number, number): Tuple indicating figure size\n",
    "    '''\n",
    "    rows = math.ceil(len(data) / cols)\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    if layout == 'row':\n",
    "        for idx, d in enumerate(data):\n",
    "            img, title = d\n",
    "\n",
    "            plt.subplot(rows, cols, idx+1)\n",
    "            plt.title(title, fontsize=20)\n",
    "            plt.axis('off')\n",
    "            if len(img.shape) == 2:\n",
    "                plt.imshow(img, cmap='gray')\n",
    "                \n",
    "            elif len(img.shape) == 3:\n",
    "                plt.imshow(img)\n",
    "                \n",
    "    elif layout == 'col':\n",
    "        counter = 0\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                img, title = data[r + rows*c]\n",
    "                nb_channels = len(img.shape)\n",
    "                \n",
    "                plt.subplot(rows, cols, counter+1)\n",
    "                plt.title(title, fontsize=20)\n",
    "                plt.axis('off')\n",
    "                if len(img.shape) == 2:\n",
    "                    plt.imshow(img, cmap='gray')\n",
    "                \n",
    "                elif len(img.shape) == 3:\n",
    "                    plt.imshow(img)\n",
    "              \n",
    "                counter += 1\n",
    "\n",
    "    return ax\n",
    "\n",
    "def capture_frames(video_path, frames_dir):\n",
    "    '''\n",
    "    Utility function that captures and stores video frames\n",
    "    :param video_path (string): Video path\n",
    "    :param frames_dir (string): Frames directory\n",
    "    '''\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    print('Starting frame capture...')\n",
    "    \n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        success, frame = cap.read()\n",
    "        cv2.imwrite(frames_dir + 'frame{:02}.jpg'.format(count), frame)\n",
    "        count += 1\n",
    "\n",
    "    print('Completed!')\n",
    "    \n",
    "\n",
    "test_img_paths = glob.glob('test_images/test*.jpg')\n",
    "sort_nicely(test_img_paths)\n",
    "\n",
    "video1 = glob.glob('video_frames/frame*.jpg')\n",
    "sort_nicely(video1)\n",
    "\n",
    "video2 = glob.glob('video_frames_1/frame*.jpg')\n",
    "sort_nicely(video2)\n",
    "\n",
    "# List of all demos to visualise\n",
    "plot_demo = [1, 2, 3, 4, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f27daa181177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loaded the saved camera calibration matrix & dist coefficients!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalibrate_camera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'camera_calib.p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'mtx'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dist'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f27daa181177>\u001b[0m in \u001b[0;36mcalibrate_camera\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgpaths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mimshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# gets only the (height, width) to be used in the cv2.calibrateCamera()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def calibrate_camera():\n",
    "    '''\n",
    "    Computes the camera calibration matrix and distortion coefficients\n",
    "    :return: Camera calibration matrix and distortion coefficients\n",
    "    '''\n",
    "    \n",
    "    imgpaths = glob.glob('camera_cal/calibration*.jpg')\n",
    "    sort_nicely(imgpaths)\n",
    "    \n",
    "    # View a sample calibration image\n",
    "    %matplotlib inline\n",
    "    \n",
    "    image = cv2.imread(imgpaths[0])\n",
    "    imshape = image.shape[:2] # gets only the (height, width) to be used in the cv2.calibrateCamera()\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    print('Image shape: {}'.format(image.shape))\n",
    "\n",
    "    %matplotlib qt\n",
    "    print()\n",
    "    print('Calibrating the camera...')\n",
    "    print()\n",
    "\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "\n",
    "    nx = 9 # Number of inside corners on each row of the chessboard\n",
    "    ny = 6 # Number of inside corners on each column of the chessboard\n",
    "\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros([ny*nx, 3], dtype=np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "\n",
    "    # Iterate over each calibration image and determine the objpoints and imgpoints\n",
    "    for idx, imgpath in enumerate(imgpaths):\n",
    "        img = cv2.imread(imgpath)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        if ret:\n",
    "            img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.waitKey(500)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, imshape[::-1], None, None)\n",
    "   \n",
    "    print('Calibration complete!')\n",
    "    cv2.destroyAllWindows()\n",
    "    return mtx, dist\n",
    "\n",
    "# Note: the calibration process only needs to be run once in the absense of the pickled file\n",
    "# containing the calculated aforementioned params\n",
    "if os.path.exists('camera_calib.p'):\n",
    "    with open('camera_calib.p', mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        mtx, dist = data['mtx'], data['dist']\n",
    "        print('Loaded the saved camera calibration matrix & dist coefficients!')\n",
    "else:\n",
    "    mtx, dist = calibrate_camera()\n",
    "    with open('camera_calib.p', mode='wb') as f:\n",
    "        pickle.dump({'mtx': mtx, 'dist': dist}, f)\n",
    "\n",
    "def undistort(img, mtx, dist):\n",
    "    '''\n",
    "    Undistorts an image\n",
    "    :param img (ndarray): Image, represented an a numpy array\n",
    "    :param mtx: Camera calibration matrix\n",
    "    :param dist: Distortion coeff's\n",
    "    :return : Undistorted image\n",
    "    '''\n",
    "    \n",
    "    undistort = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undistort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort a sample camera calibration image and a sample test image\n",
    "\n",
    "if 1 in plot_demo:\n",
    "    ccimg = cv2.imread('camera_cal/calibration1.jpg')\n",
    "    ccimg_undist = undistort(ccimg, mtx, dist)\n",
    "\n",
    "    plot_images([\n",
    "        (ccimg, 'Original Image'),\n",
    "        (ccimg_undist, 'Undistorted Image')\n",
    "    ])\n",
    "    \n",
    "    img_orig = mpimg.imread(test_img_paths[1])\n",
    "    img = undistort(img_orig, mtx, dist)\n",
    "\n",
    "    plot_images([\n",
    "        (img_orig, 'Original Image'),\n",
    "        (img, 'Undistorted Image')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (720, 1280)\n",
    "\n",
    "def get_roi(img, vertices):\n",
    "    '''\n",
    "    Transforms an image by preserving only the ROI represented by the\n",
    "    the 'vertices' and removes the remainder of the image by setting the pixel intensity to 0\n",
    "    :param img (ndarray): Image\n",
    "    :param vertices (ndarray): Region of Interest of the image\n",
    "    :return : Modified image\n",
    "    '''\n",
    "    \n",
    "    vertices = np.array(vertices, ndmin=3, dtype=np.int32)\n",
    "    if len(img.shape) == 3:\n",
    "        fill_color = (255,) * 3\n",
    "    else:\n",
    "        fill_color = 255\n",
    "            \n",
    "    mask = np.zeros_like(img)\n",
    "    mask = cv2.fillPoly(mask, vertices, fill_color)\n",
    "    return cv2.bitwise_and(img, mask)\n",
    "    \n",
    "def warp_image(img, warp_shape, src, dst):\n",
    "    '''\n",
    "    Performs perspective transformation (PT)\n",
    "    :param img (ndarray): Image\n",
    "    :param warp_shape: Shape of the warped image\n",
    "    :param src (ndarray): Source points\n",
    "    :param dst (ndarray): Destination points\n",
    "    :return : Tuple (Transformed image, PT matrix, PT inverse matrix)\n",
    "    '''\n",
    "    \n",
    "    # Get the perspective transformation matrix and its inverse\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    invM = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # Warp the image\n",
    "    warped = cv2.warpPerspective(img, M, warp_shape, flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, invM\n",
    "\n",
    "def preprocess_image(img, visualise=False):\n",
    "    '''\n",
    "    Pre-processes an image. Steps include:\n",
    "    1. Distortion correction\n",
    "    2. Perspective Transformation\n",
    "    3. ROI crop\n",
    "    \n",
    "    :param img (ndarray): Original Image\n",
    "    :param visualise (boolean): Boolean flag for visualisation\n",
    "    :return : Pre-processed image, (PT matrix, PT inverse matrix)\n",
    "    '''\n",
    "    \n",
    "    ysize = img.shape[0]\n",
    "    xsize = img.shape[1]\n",
    "    \n",
    "    # 1. Distortion correction\n",
    "    undist = undistort(img, mtx, dist)\n",
    "    \n",
    "    # 2. Perspective transformation\n",
    "    src = np.float32([\n",
    "        (850,300),    \n",
    "        (350,300), \n",
    "        (40,700),  \n",
    "        (1160,700)\n",
    "    ])\n",
    "\n",
    "    dst = np.float32([\n",
    "        (xsize - 350, 0),\n",
    "        (350, 0),\n",
    "        (350, ysize),\n",
    "        (xsize - 350, ysize)\n",
    "    ])\n",
    "\n",
    "    warped, M, invM = warp_image(undist, (xsize, ysize), src, dst)\n",
    "\n",
    "    # 3. ROI crop\n",
    "    vertices = np.array([\n",
    "        [200, ysize],\n",
    "        [200, 0],\n",
    "        [1100, 0],\n",
    "        [1100, ysize]\n",
    "    ])\n",
    "\n",
    "    roi = get_roi(warped, vertices)\n",
    "\n",
    "    # 4. Visualise the transformation\n",
    "    if visualise:\n",
    "        img_copy = np.copy(img)\n",
    "        roi_copy = np.copy(roi)\n",
    "        \n",
    "        cv2.polylines(img_copy, [np.int32(src)], True, (255, 0, 0), 3)\n",
    "        cv2.polylines(roi_copy, [np.int32(dst)], True, (255, 0, 0), 3)\n",
    "        \n",
    "        plot_images([\n",
    "            (img_copy, 'Original Image'),\n",
    "            (roi_copy, 'Bird\\'s Eye View Perspective')\n",
    "        ])\n",
    "\n",
    "    return roi, (M, invM)\n",
    "\n",
    "def get_image(img_path, visualise=False):\n",
    "    '''\n",
    "    Load an image from the 'img_path' and pre-process it\n",
    "    :param img_path (string): Image path\n",
    "    :param visualise (boolean): Boolean flag for visualisation\n",
    "    :return : Transformed Image, (PT matrix, PT inv matrix)\n",
    "    '''\n",
    "    img = mpimg.imread(img_path)\n",
    "    return preprocess_image(img, visualise=visualise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2 in plot_demo:\n",
    "    for path in test_img_paths[0:1]:\n",
    "        get_image(path, visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_threshold(img, low, high):    \n",
    "    if len(img.shape) == 2:\n",
    "        output = np.zeros_like(img)\n",
    "        mask = (img >= low) & (img <= high)\n",
    "        \n",
    "    elif len(img.shape) == 3:\n",
    "        output = np.zeros_like(img[:,:,0])\n",
    "        mask = (img[:,:,0] >= low[0]) & (img[:,:,0] <= high[0]) \\\n",
    "            & (img[:,:,1] >= low[1]) & (img[:,:,1] <= high[1]) \\\n",
    "            & (img[:,:,2] >= low[2]) & (img[:,:,2] <= high[2])\n",
    "            \n",
    "    output[mask] = 1\n",
    "    return output\n",
    "\n",
    "def get_binary_image(img, visualise=False):\n",
    "    \"\"\"\n",
    "    Generate a thresholded binary image using transforms from an ensemble of color spaces: \n",
    "    LAB (Yellow), HSV (Yellow + White), HLS (Yellow + White), RGB (White) and \n",
    "    Adaptive Thresholding ()\n",
    "    :param img (ndarray): Warped image\n",
    "    :param visualise (boolean): Boolean flag for visualisation\n",
    "    :return (ndarray): Thresholded binary image\n",
    "    \"\"\"\n",
    "    \n",
    "    ### LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    L = lab[:,:,0]\n",
    "    L_max, L_mean = np.max(L), np.mean(L)\n",
    "    B = lab[:,:,2]\n",
    "    B_max, B_mean = np.max(B), np.mean(B)\n",
    "\n",
    "    # YELLOW\n",
    "    L_adapt_yellow = max(80, int(L_max * 0.45))\n",
    "    B_adapt_yellow =  max(int(B_max * 0.70), int(B_mean * 1.2))\n",
    "    lab_low_yellow = np.array((L_adapt_yellow, 120, B_adapt_yellow))\n",
    "    lab_high_yellow = np.array((255, 145, 255))\n",
    "\n",
    "    lab_yellow = binary_threshold(lab, lab_low_yellow, lab_high_yellow)\n",
    "    lab_binary =lab_yellow\n",
    "      \n",
    "    ### HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    H = hsv[:,:,0]\n",
    "    H_max, H_mean = np.max(H), np.mean(H)\n",
    "    S = hsv[:,:,1]\n",
    "    S_max, S_mean = np.max(S), np.mean(S)\n",
    "    V = hsv[:,:,2]\n",
    "    V_max, V_mean = np.max(V), np.mean(V)\n",
    "    \n",
    "    # YELLOW\n",
    "    S_adapt_yellow =  max(int(S_max * 0.25), int(S_mean * 1.75))\n",
    "    V_adapt_yellow =  max(50, int(V_mean * 1.25))\n",
    "    hsv_low_yellow = np.array((15, S_adapt_yellow, V_adapt_yellow))\n",
    "   \n",
    "    hsv_high_yellow = np.array((30, 255, 255))\n",
    "    hsv_yellow = binary_threshold(hsv, hsv_low_yellow, hsv_high_yellow)    \n",
    "\n",
    "    # WHITE\n",
    "    V_adapt_white = max(150, int(V_max * 0.8),int(V_mean * 1.25))\n",
    "    hsv_low_white = np.array((0, 0, V_adapt_white))\n",
    "    hsv_high_white = np.array((255, 40, 220))\n",
    "\n",
    "    hsv_white = binary_threshold(hsv, hsv_low_white, hsv_high_white)\n",
    "\n",
    "    hsv_binary = hsv_yellow | hsv_white\n",
    "\n",
    "    ### HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    L = hls[:,:,1]\n",
    "    L_max, L_mean = np.max(L), np.mean(L)\n",
    "    S = hls[:,:,2]\n",
    "    S_max, S_mean = np.max(S), np.mean(S)\n",
    " \n",
    "    # YELLOW\n",
    "    L_adapt_yellow = max(80, int(L_mean * 1.25))\n",
    "    S_adapt_yellow = max(int(S_max * 0.25), int(S_mean * 1.75))\n",
    "    hls_low_yellow = np.array((15, L_adapt_yellow, S_adapt_yellow))\n",
    "    hls_high_yellow = np.array((30, 255, 255))\n",
    "\n",
    "    hls_yellow = binary_threshold(hls, hls_low_yellow, hls_high_yellow)\n",
    "    \n",
    "    # WHITE\n",
    "    L_adapt_white =  max(160, int(L_max *0.8),int(L_mean * 1.25))\n",
    "    hls_low_white = np.array((0, L_adapt_white,  0))\n",
    "    hls_high_white = np.array((255, 255, 255))\n",
    "\n",
    "    hls_white = binary_threshold(hls, hls_low_white, hls_high_white)\n",
    "        \n",
    "    hls_binary = hls_yellow | hls_white\n",
    "\n",
    "    ### R color channel (WHITE)\n",
    "    R = img[:,:,0]\n",
    "    R_max, R_mean = np.max(R), np.mean(R)\n",
    "    \n",
    "    R_low_white = min(max(150, int(R_max * 0.55), int(R_mean * 1.95)),230)\n",
    "    R_binary = binary_threshold(R, R_low_white, 255)\n",
    "    \n",
    "    ### Adaptive thresholding: Gaussian kernel \n",
    "    # YELLOW\n",
    "    \n",
    "    adapt_yellow_S = cv2.adaptiveThreshold(hls[:,:,2], 1, \\\n",
    "                                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 161, -5)\n",
    "    adapt_yellow_B = cv2.adaptiveThreshold(lab[:,:,2], 1, \\\n",
    "                                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 161, -5)\n",
    "    adapt_yellow = adapt_yellow_S & adapt_yellow_B\n",
    "    \n",
    "    # WHITE\n",
    "    adapt_white_R = cv2.adaptiveThreshold(img[:,:,0], 1, \\\n",
    "                                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 161, -27)\n",
    "    adapt_white_L = cv2.adaptiveThreshold(hsv[:,:,2], 1, \\\n",
    "                                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 161, -27)\n",
    "    adapt_white = adapt_white_R & adapt_white_L\n",
    "    \n",
    "                                                  \n",
    "    adapt_binary =  adapt_yellow | adapt_white\n",
    "\n",
    "    ### Ensemble Voting\n",
    "    combined = np.asarray(R_binary + lab_binary + hls_binary + hsv_binary + adapt_binary, dtype=np.uint8)\n",
    "\n",
    "    combined[combined < 3] = 0\n",
    "    combined[combined >= 3] = 1\n",
    "\n",
    "    if visualise:\n",
    "        plot_images([\n",
    "            (img, 'Original'),\n",
    "            (R_binary, 'R'),\n",
    "            (hls_binary, 'HLS'),\n",
    "            (hsv_binary, 'HSV'),\n",
    "            (lab_binary, 'LAB'),\n",
    "            (adapt_binary, 'Adaptive Thresh'),\n",
    "            (combined, 'Combined'),\n",
    "#             (hls_white, 'hls_white'),\n",
    "#             (hls_yellow, 'hls yellow'),\n",
    "#             (lab_white, 'lab white'),\n",
    "#             (lab_yellow, 'lab yello'),\n",
    "        ], figsize=(32, 42))\n",
    "\n",
    "    return  combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 3 in plot_demo:\n",
    "    for img_path in test_img_paths[:2]: #video2[5:10]:\n",
    "        img, _ = get_image(img_path)\n",
    "        get_binary_image(img, visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly_points(left_fit, right_fit):\n",
    "    '''\n",
    "    Get the points for the left lane/ right lane defined by the polynomial coeff's 'left_fit'\n",
    "    and 'right_fit'\n",
    "    :param left_fit (ndarray): Coefficients for the polynomial that defines the left lane line\n",
    "    :param right_fit (ndarray): Coefficients for the polynomial that defines the right lane line\n",
    "    : return (Tuple(ndarray, ndarray, ndarray, ndarray)): x-y coordinates for the left and right lane lines\n",
    "    '''\n",
    "    ysize, xsize = IMG_SHAPE\n",
    "    \n",
    "    # Get the points for the entire height of the image\n",
    "    plot_y = np.linspace(0, ysize-1, ysize)\n",
    "    plot_xleft = left_fit[0] * plot_y**2 + left_fit[1] * plot_y + left_fit[2]\n",
    "    plot_xright = right_fit[0] * plot_y**2 + right_fit[1] * plot_y + right_fit[2]\n",
    "    \n",
    "    # But keep only those points that lie within the image\n",
    "    plot_xleft = plot_xleft[(plot_xleft >= 0) & (plot_xleft <= xsize - 1)]\n",
    "    plot_xright = plot_xright[(plot_xright >= 0) & (plot_xright <= xsize - 1)]\n",
    "    plot_yleft = np.linspace(ysize - len(plot_xleft), ysize - 1, len(plot_xleft))\n",
    "    plot_yright = np.linspace(ysize - len(plot_xright), ysize - 1, len(plot_xright))\n",
    "    \n",
    "    return plot_xleft.astype(np.int), plot_yleft.astype(np.int), plot_xright.astype(np.int), plot_yright.astype(np.int)\n",
    "\n",
    "def check_validity(left_fit, right_fit, diagnostics=False):\n",
    "    '''\n",
    "    Determine the validity of lane lines represented by a set of second order polynomial coefficients \n",
    "    :param left_fit (ndarray): Coefficients for the 2nd order polynomial that defines the left lane line\n",
    "    :param right_fit (ndarray): Coefficients for the 2nd order polynomial that defines the right lane line\n",
    "    :param diagnostics (boolean): Boolean flag for logging\n",
    "    : return (boolean)\n",
    "    '''\n",
    "    \n",
    "    if left_fit is None or right_fit is None:\n",
    "        return False\n",
    "    \n",
    "    plot_xleft, plot_yleft, plot_xright, plot_yright = get_poly_points(left_fit, right_fit)\n",
    "\n",
    "    # Check whether the two lines lie within a plausible distance from one another for three distinct y-values\n",
    "\n",
    "    y1 = IMG_SHAPE[0] - 1 # Bottom\n",
    "    y2 = IMG_SHAPE[0] - int(min(len(plot_yleft), len(plot_yright)) * 0.35) # For the 2nd and 3rd, take values between y1 and the top-most available value.\n",
    "    y3 = IMG_SHAPE[0] - int(min(len(plot_yleft), len(plot_yright)) * 0.75)\n",
    "\n",
    "    # Compute the respective x-values for both lines\n",
    "    x1l = left_fit[0]  * (y1**2) + left_fit[1]  * y1 + left_fit[2]\n",
    "    x2l = left_fit[0]  * (y2**2) + left_fit[1]  * y2 + left_fit[2]\n",
    "    x3l = left_fit[0]  * (y3**2) + left_fit[1]  * y3 + left_fit[2]\n",
    "\n",
    "    x1r = right_fit[0] * (y1**2) + right_fit[1] * y1 + right_fit[2]\n",
    "    x2r = right_fit[0] * (y2**2) + right_fit[1] * y2 + right_fit[2]\n",
    "    x3r = right_fit[0] * (y3**2) + right_fit[1] * y3 + right_fit[2]\n",
    "\n",
    "    # Compute the L1 norms\n",
    "    x1_diff = abs(x1l - x1r)\n",
    "    x2_diff = abs(x2l - x2r)\n",
    "    x3_diff = abs(x3l - x3r)\n",
    "\n",
    "    # Define the threshold values for each of the three points\n",
    "    min_dist_y1 = 480 # 510 # 530 \n",
    "    max_dist_y1 = 730 # 750 # 660\n",
    "    min_dist_y2 = 280\n",
    "    max_dist_y2 = 730 # 660\n",
    "    min_dist_y3 = 140\n",
    "    max_dist_y3 = 730 # 660\n",
    "    \n",
    "    if (x1_diff < min_dist_y1) | (x1_diff > max_dist_y1) | \\\n",
    "        (x2_diff < min_dist_y2) | (x2_diff > max_dist_y2) | \\\n",
    "        (x3_diff < min_dist_y3) | (x3_diff > max_dist_y3):\n",
    "        if diagnostics:\n",
    "            print(\"Violated distance criterion: \" +\n",
    "                  \"x1_diff == {:.2f}, x2_diff == {:.2f}, x3_diff == {:.2f}\".format(x1_diff, x2_diff, x3_diff))\n",
    "        return False\n",
    "\n",
    "    # Check whether the line slopes are similar for two distinct y-values\n",
    "    # x = Ay**2 + By + C\n",
    "    # dx/dy = 2Ay + B\n",
    "    \n",
    "    y1left_dx  = 2 * left_fit[0]  * y1 + left_fit[1]\n",
    "    y3left_dx  = 2 * left_fit[0]  * y3 + left_fit[1]\n",
    "    y1right_dx = 2 * right_fit[0] * y1 + right_fit[1]\n",
    "    y3right_dx = 2 * right_fit[0] * y3 + right_fit[1]\n",
    "\n",
    "    # Compute the L1-norm\n",
    "    norm1 = abs(y1left_dx - y1right_dx)\n",
    "    norm2 = abs(y3left_dx - y3right_dx)\n",
    "    \n",
    "#     if diagnostics: print( norm1, norm2)\n",
    "\n",
    "    # Define the L1 norm threshold\n",
    "    thresh = 0.6 #0.58 \n",
    "    if (norm1 >= thresh) | (norm2 >= thresh):\n",
    "        if diagnostics:\n",
    "            print(\"Violated tangent criterion: \" +\n",
    "                  \"norm1 == {:.3f}, norm2 == {:.3f} (thresh == {}).\".format(norm1, norm2, thresh))\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def polyfit_sliding_window(binary, lane_width_px=578, visualise=False, diagnostics=False):\n",
    "    '''\n",
    "    Detect lane lines in a thresholded binary image using the sliding window technique\n",
    "    :param binary (ndarray): Thresholded binary image\n",
    "    :param lane_width_px (int): Average lane line width (in px) for the warped image \n",
    "    computed empirically\n",
    "    :param visualise (boolean): Boolean flag for visualisation\n",
    "    :param diagnositics (boolean): Boolean flag for logging\n",
    "    '''\n",
    "    \n",
    "    global cache\n",
    "    ret = True\n",
    "\n",
    "    # Sanity check\n",
    "    if binary.max() <= 0:\n",
    "        return False, np.array([]), np.array([]), np.array([])\n",
    "    \n",
    "    # Step 1: Compute the histogram along all the columns in the lower half of the image. \n",
    "    # The two most prominent peaks in this histogram will be good indicators of the\n",
    "    # x-position of the base of the lane lines\n",
    "    histogram = None\n",
    "    cutoffs = [int(binary.shape[0] / 2), 0]\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        histogram = np.sum(binary[cutoff:, :], axis=0)\n",
    "        \n",
    "        if histogram.max() > 0:\n",
    "            break\n",
    "\n",
    "    if histogram.max() == 0:\n",
    "        print('Unable to detect lane lines in this frame. Trying another frame!')\n",
    "        return False, np.array([]), np.array([])\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0] / 2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    if visualise:\n",
    "        plot_images([(binary, 'Binary')])\n",
    "        plt.plot(histogram, 'm', linewidth=4.0)\n",
    "        plt.plot((midpoint, midpoint), (0, IMG_SHAPE[0]), 'c')\n",
    "        plt.plot((0, IMG_SHAPE[1]), (cutoff, cutoff), 'c')\n",
    "\n",
    "    out = np.dstack((binary, binary, binary)) * 255\n",
    "\n",
    "    nb_windows = 12 # number of sliding windows\n",
    "    margin = 100 # width of the windows +/- margin\n",
    "    minpix = 50 # min number of pixels needed to recenter the window\n",
    "    window_height = int(IMG_SHAPE[0] / nb_windows)\n",
    "    min_lane_pts = 10  # min number of 'hot' pixels needed to fit a 2nd order polynomial as a \n",
    "                    # lane line\n",
    "    \n",
    "    # Identify the x-y positions of all nonzero pixels in the image\n",
    "    # Note: the indices here are equivalent to the coordinate locations of the\n",
    "    # pixel\n",
    "    nonzero = binary.nonzero()\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    for window in range(nb_windows):\n",
    "        # Identify window boundaries in x and y (and left and right)\n",
    "        win_y_low = IMG_SHAPE[0] - (1 + window) * window_height\n",
    "        win_y_high = IMG_SHAPE[0] - window * window_height\n",
    "\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Draw windows for visualisation\n",
    "        cv2.rectangle(out, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high),\\\n",
    "                      (0, 255, 0), 2)\n",
    "        cv2.rectangle(out, (win_xright_low, win_y_low), (win_xright_high, win_y_high),\\\n",
    "                      (0, 255, 0), 2)\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy <= win_y_high)\n",
    "                         & (nonzerox >= win_xleft_low) & (nonzerox <= win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy <= win_y_high)\n",
    "                         & (nonzerox >= win_xright_low) & (nonzerox <= win_xright_high)).nonzero()[0]\n",
    "\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) >  minpix:\n",
    "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract pixel positions for the left and right lane lines\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    left_fit, right_fit = None, None\n",
    "    \n",
    "    # Sanity check; Fit a 2nd order polynomial for each lane line pixels\n",
    "    if len(leftx) >= min_lane_pts and len(rightx) >= min_lane_pts:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Validate detected lane lines\n",
    "    valid = check_validity(left_fit, right_fit, diagnostics=diagnostics)\n",
    "   \n",
    "    if not valid:\n",
    "        # If the detected lane lines are NOT valid:\n",
    "        # 1. Compute the lane lines as an average of the previously detected lines\n",
    "        # from the cache and flag this detection cycle as a failure by setting ret=False\n",
    "        # 2. Else, if cache is empty, return \n",
    "        \n",
    "        if len(cache) == 0:\n",
    "            if diagnostics: print('WARNING: Unable to detect lane lines in this frame.')\n",
    "            return False, np.array([]), np.array([])\n",
    "        \n",
    "        avg_params = np.mean(cache, axis=0)\n",
    "        left_fit, right_fit = avg_params[0], avg_params[1]\n",
    "        ret = False\n",
    "        \n",
    "    plot_xleft, plot_yleft, plot_xright, plot_yright = get_poly_points(left_fit, right_fit)\n",
    "\n",
    "    # Color the detected pixels for each lane line\n",
    "    out[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [255, 10, 255]\n",
    "\n",
    "    left_poly_pts = np.array([np.transpose(np.vstack([plot_xleft, plot_yleft]))])\n",
    "    right_poly_pts = np.array([np.transpose(np.vstack([plot_xright, plot_yright]))])\n",
    "\n",
    "    # Plot the fitted polynomial\n",
    "    cv2.polylines(out, np.int32([left_poly_pts]), isClosed=False, color=(200,255,155), thickness=4)\n",
    "    cv2.polylines(out, np.int32([right_poly_pts]), isClosed=False, color=(200,255,155), thickness=4)\n",
    "\n",
    "    if visualise:\n",
    "        plot_images([(img, 'Original'), (out, 'Out')], figsize=(30, 40))\n",
    "        \n",
    "    return ret, out, np.array([left_fit, right_fit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 4 in plot_demo:\n",
    "\n",
    "    cache = np.array([])\n",
    "\n",
    "    for img_path in test_img_paths[:]: #video2[134:138]:\n",
    "        img, _ = get_image(img_path)\n",
    "        binary = get_binary_image(img, visualise=False)\n",
    "        polyfit_sliding_window(binary, visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyfit_adapt_search(img, prev_poly_param, visualise=False, diagnostics=False):\n",
    "    '''\n",
    "    Function that: \n",
    "    1. Uses the sliding window technique to perform incremental localised adaptive threhsolding\n",
    "    over the previosuly detected lane line trajectory to develop a threhsolded binary image. Then,\n",
    "    2. Uses this generated binary image to detect and fit lane lines in a margin around the previous fit rather \n",
    "    than performing a blind search\n",
    "    :param img (ndarray): Warped image\n",
    "    :param prev_poly_param (ndarray): Polynomial coefficients of the previously detected lane lines\n",
    "    :param visualise (boolean): Boolean flag for visualisation\n",
    "    :param diagnostics (boolean): Boolean flag for logging\n",
    "    : return (ndarray, ndarray): 3 channel image with the newly detected lane lines, current polynomial coefficients\n",
    "    '''\n",
    "    \n",
    "    global cache # Cache of the previosuly detected lane line coefficients\n",
    "    global attempts # Number of retries before the pipeline is RESET to detect lines via the smoothing window aproach\n",
    "    \n",
    "    # Sanity check\n",
    "    assert(len(img.shape) == 3)\n",
    "    \n",
    "    # Setup\n",
    "    nb_windows = 10 # Number of windows over which to perform the localised color thresholding  \n",
    "    bin_margin = 80 # Width of the windows +/- margin for localised thresholding\n",
    "    margin = 60 # Width around previous line positions +/- margin around which to search for the new lines\n",
    "    window_height = int(img.shape[0] / nb_windows)\n",
    "    smoothing_window = 5 # Number of frames over which to compute the Moving Average\n",
    "    min_lane_pts = 10\n",
    "    \n",
    "    binary = np.zeros_like(img[:,:,0]) # Placeholder for the thresholded binary image\n",
    "    img_plot = np.copy(img)\n",
    "        \n",
    "    left_fit, right_fit = prev_poly_param[0], prev_poly_param[1]\n",
    "    plot_xleft, plot_yleft, plot_xright, plot_yright = get_poly_points(left_fit, right_fit)\n",
    "    \n",
    "    leftx_current = np.int(plot_xleft[-1])\n",
    "    rightx_current = np.int(plot_xright[-1])\n",
    "    \n",
    "    # Iterate over the windows, perform localised color thresholding and generate the binary image\n",
    "    for window in range(nb_windows):\n",
    "        # Identify window boundaries in x and y (and left and right)\n",
    "        win_y_low = IMG_SHAPE[0] - (window + 1) * window_height\n",
    "        win_y_high = IMG_SHAPE[0] - window * window_height\n",
    "        win_xleft_low = min(max(0, leftx_current - bin_margin), 1280)\n",
    "        win_xleft_high = min(max(0, leftx_current + bin_margin), 1280)\n",
    "        win_xright_low = min(max(0, rightx_current - bin_margin), 1280)\n",
    "        win_xright_high = min(max(0, rightx_current + bin_margin), 1280)\n",
    "\n",
    "        img_win_left = img[win_y_low:win_y_high, win_xleft_low:win_xleft_high,:]\n",
    "        binary[win_y_low:win_y_high, win_xleft_low:win_xleft_high] = \\\n",
    "            get_binary_image(img_win_left, visualise=False)\n",
    "\n",
    "        img_win_right = img[win_y_low:win_y_high, win_xright_low:win_xright_high, :]\n",
    "        binary[win_y_low:win_y_high, win_xright_low:win_xright_high] = \\\n",
    "            get_binary_image(img_win_right, visualise=False)\n",
    "\n",
    "        # Given that we only keep the points/values for a line that lie within the image\n",
    "        # (see 'get_poly_points'), the overall length and consequently number of points (i.e. x-values\n",
    "        # and y-values) can be < the length of the image. As a result, we check for the presence\n",
    "        # of the current window's lower y-value i.e 'win_y_low' as a valid point within the previously detected line\n",
    "        # If, a point associated with this y-value exists, we update the x-position of the next window with\n",
    "        # the corresponding x-value.\n",
    "        # Else, we keep the x-position of the subsequent windows the same and move up the image\n",
    "        idxs = np.where(plot_yleft == win_y_low)[0]\n",
    "        if len(idxs) != 0:\n",
    "            leftx_current = int(plot_xleft[idxs[0]])\n",
    "            \n",
    "        idxs = np.where(plot_yright == win_y_low)[0]\n",
    "        if len(idxs) != 0:\n",
    "            rightx_current = int(plot_xright[idxs[0]])\n",
    "\n",
    "        if visualise:\n",
    "            left_pts = np.array([np.transpose(np.vstack([plot_xleft, plot_yleft]))])\n",
    "            right_pts = np.array([np.transpose(np.vstack([plot_xright, plot_yright]))])\n",
    "            \n",
    "            # Plot the previously detected lane lines\n",
    "            cv2.polylines(img_plot, np.int32([left_pts]), isClosed=False, color=(255, 20, 147), thickness=4)\n",
    "            cv2.polylines(img_plot, np.int32([right_pts]), isClosed=False, color=(255, 20, 147), thickness=4)    \n",
    "            \n",
    "            bin_win_left = binary[win_y_low:win_y_high, win_xleft_low:win_xleft_high]\n",
    "            bin_win_left = np.dstack((bin_win_left, np.zeros_like(bin_win_left), np.zeros_like(bin_win_left))) * 255\n",
    "\n",
    "            bin_win_right = binary[win_y_low:win_y_high, win_xright_low:win_xright_high]\n",
    "            bin_win_right = np.dstack([np.zeros_like(bin_win_right), np.zeros_like(bin_win_right), bin_win_right]) * 255\n",
    "            \n",
    "            # Blend the localised image window with its corresponding thresholded binary version\n",
    "            win_left = cv2.addWeighted(bin_win_left, 0.5, img_win_left, 0.7, 0)\n",
    "            win_right = cv2.addWeighted(bin_win_right, 0.5, img_win_right, 0.7, 0)\n",
    "            \n",
    "            # Draw the binary search window\n",
    "            cv2.rectangle(img_plot, (win_xleft_low,win_y_low), (win_xleft_high,win_y_high), (0,255,0), 5)\n",
    "            cv2.rectangle(img_plot, (win_xright_low,win_y_low), (win_xright_high,win_y_high), (0,255,0), 5)\n",
    "            \n",
    "            f, _ = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "            plt.subplot(121)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(binary, cmap='gray')\n",
    "\n",
    "            plt.subplot(122)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img_plot)\n",
    "\n",
    "            plt.subplots_adjust(top=0.98, bottom=0.0, left=0.0, right=1.0, hspace=0.1, wspace=0.05)\n",
    "            plt.savefig('./gif_images/window1{:02}.png'.format(window))\n",
    "            \n",
    "            # The blended Binary window and Image window is added later for better visualisation\n",
    "            img_plot[win_y_low:win_y_high, win_xleft_low:win_xleft_high] = win_left\n",
    "            img_plot[win_y_low:win_y_high, win_xright_low:win_xright_high] = win_right\n",
    "        \n",
    "    # Identify the x-y coordinates of all the non-zero pixels from the binary image\n",
    "    # generated above\n",
    "    nonzero = binary.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Extract all the \n",
    "    left_lane_inds = \\\n",
    "        ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) &\n",
    "        (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "    right_lane_inds = \\\n",
    "        ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) &\n",
    "         (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Sanity checks\n",
    "    if len(leftx) > min_lane_pts:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    else:\n",
    "        if diagnostics: print('WARNING: Less than {} pts detected for the left lane. {}'.format(min_lane_pts, len(leftx)))\n",
    "\n",
    "    if len(rightx) > min_lane_pts:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    else:\n",
    "        if diagnostics: print('WARNING: Less than {} pts detected for the right lane. {}'.format(min_lane_pts, len(rightx)))\n",
    "        \n",
    "    valid = check_validity(left_fit, right_fit, diagnostics=diagnostics)\n",
    "\n",
    "    # Perform smoothing via moving average\n",
    "    if valid:\n",
    "        if len(cache) < smoothing_window:\n",
    "            cache = np.concatenate((cache, [np.array([left_fit, right_fit])]), axis=0)\n",
    "        elif len(cache) >= smoothing_window:\n",
    "            cache[:-1] = cache[1:]\n",
    "            cache[-1] = np.array([left_fit, right_fit])\n",
    "  \n",
    "        avg_params = np.mean(cache, axis=0)\n",
    "        left_fit, right_fit = avg_params[0], avg_params[1]\n",
    "        plot_xleft, plot_yleft, plot_xright, plot_yright = get_poly_points(left_fit, right_fit)\n",
    "        curr_poly_param = np.array([left_fit, right_fit])\n",
    "    else:\n",
    "        attempts += 1\n",
    "        curr_poly_param = prev_poly_param\n",
    "    \n",
    "    out = np.dstack([binary, binary, binary]) * 255\n",
    "    win_img = np.zeros_like(out)\n",
    "\n",
    "    # Color the lane line pixels\n",
    "    out[lefty, leftx] = [255, 0, 0]\n",
    "    out[righty, rightx] = [255, 10, 255]\n",
    "\n",
    "    left_window1 = np.array([np.transpose(np.vstack([plot_xleft - margin, plot_yleft]))])\n",
    "    left_window2 = np.array([np.flipud(np.transpose(np.vstack([plot_xleft + margin, plot_yleft])))])\n",
    "    left_pts = np.hstack([left_window1, left_window2])\n",
    "\n",
    "    right_window1 = np.array([np.transpose(np.vstack([plot_xright - margin, plot_yright]))])\n",
    "    right_window2 = np.array([np.flipud(np.transpose(np.vstack([plot_xright + margin, plot_yright])))])\n",
    "    right_pts = np.hstack([right_window1, right_window2])\n",
    "\n",
    "    # Draw the search boundary\n",
    "    cv2.fillPoly(win_img, np.int_([left_pts]), (0, 255, 0))\n",
    "    cv2.fillPoly(win_img, np.int_([right_pts]), (0, 255, 0))\n",
    "\n",
    "    out = cv2.addWeighted(out, 1, win_img, 0.25, 0)\n",
    "\n",
    "    left_poly_pts = np.array([np.transpose(np.vstack([plot_xleft, plot_yleft]))])\n",
    "    right_poly_pts = np.array([np.transpose(np.vstack([plot_xright, plot_yright]))])\n",
    "\n",
    "    # Draw the fit lane lines\n",
    "    cv2.polylines(out, np.int32([left_poly_pts]), isClosed=False, color=(200,255,155), thickness=4)\n",
    "    cv2.polylines(out, np.int32([right_poly_pts]), isClosed=False, color=(200,255,155), thickness=4)\n",
    "\n",
    "    return out, curr_poly_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 5 in plot_demo:\n",
    "    cache = np.array([])\n",
    "    attempts = 0\n",
    "    max_attempts = 4\n",
    "    reset = True\n",
    "    #video2 = glob.glob('video_frames_1/frame*.jpg')\n",
    "    for frame_path in test_img_paths[2:5]:\n",
    "        img = mpimg.imread(frame_path)\n",
    "        warped, (M, invM) = get_image(frame_path)\n",
    "        \n",
    "        if reset == True:\n",
    "            binary = get_binary_image(warped)\n",
    "            ret, out, poly_param = polyfit_sliding_window(binary, visualise=False, diagnostics=True)\n",
    "            if ret:\n",
    "                reset = False\n",
    "                cache = np.array([poly_param])\n",
    "                \n",
    "        else:\n",
    "            out, poly_param = polyfit_adapt_search(warped, poly_param, visualise=False, diagnostics=False)\n",
    "            if attempts == max_attempts:\n",
    "                attempts = 0\n",
    "                reset = True\n",
    "        \n",
    "            out_unwarped = cv2.warpPerspective(out, invM, (IMG_SHAPE[1], IMG_SHAPE[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "            img_overlay = np.copy(img)\n",
    "            img_overlay = cv2.addWeighted(out_unwarped, 0.5, img, 0.5, 0)\n",
    "            \n",
    "            plot_images([(warped, 'Original'), (out, 'Out'), (img_overlay, 'Overlay')], figsize=(20, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mppx(img, dashed_line_loc, visualise=False):\n",
    "    '''\n",
    "    Converts from pixel space to real world space and calculates the metres/pixel\n",
    "    :param img (ndarray): Warped Image\n",
    "    :param dashed_line_loc (string): Dashed line location (left/right)\n",
    "    :param visualise (boolean): Boolean flag for visualisation\n",
    "    : return (float32, float32): (metres/pixel y direction, metres/pixel x-direction)\n",
    "    '''\n",
    "    lane_width = 3.7\n",
    "    dashed_line_len = 3.048\n",
    "    \n",
    "    if dashed_line_loc == 'left':\n",
    "        y_top = 295\n",
    "        y_bottom = 405\n",
    "    elif dashed_line_loc == 'right':\n",
    "        y_top = 395\n",
    "        y_bottom = 495\n",
    "        \n",
    "    binary = get_binary_image(img)\n",
    "    histogram = np.sum(binary[int(binary.shape[0] / 2):, :], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0] / 2)\n",
    "    \n",
    "    x_left = np.argmax(histogram[:midpoint])\n",
    "    x_right = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    x_mppx = lane_width / (x_right - x_left)\n",
    "    y_mppx = dashed_line_len / (y_bottom - y_top)\n",
    "    \n",
    "    if visualise:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if dashed_line_loc == 'left':\n",
    "            plt.plot((x_left, x_left), (y_top, y_bottom), 'r')\n",
    "            plt.text(x_left + 10, (y_top + y_bottom) // 2, '{} m'.format(dashed_line_len), color='r', fontsize=20)\n",
    "\n",
    "        elif dashed_line_loc == 'right':\n",
    "            plt.plot((x_right, x_right), (y_top, y_bottom), 'r')\n",
    "            plt.text(x_right + 10, (y_top + y_bottom) // 2, '{} m'.format(dashed_line_len), color='r',fontsize=20)\n",
    "\n",
    "        plt.plot((x_left, x_right), (img.shape[0] - 200 , img.shape[0] - 200), 'r')\n",
    "        plt.text((x_left + x_right) // 2, img.shape[0] - 220, '{} m'.format(lane_width), color='r', fontsize=20)\n",
    "        \n",
    "    return y_mppx, x_mppx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 6 in plot_demo:\n",
    "    visualise = True\n",
    "else:\n",
    "    visualise = False\n",
    "\n",
    "img, _ = get_image(test_img_paths[0])\n",
    "y_mppx1, x_mppx1 = compute_mppx(img, dashed_line_loc='right', visualise=visualise)\n",
    "\n",
    "img, _ = get_image(test_img_paths[1])\n",
    "y_mppx2, x_mppx2 = compute_mppx(img, dashed_line_loc='left', visualise=visualise)\n",
    "\n",
    "x_mppx = (x_mppx1 + x_mppx2) / 2\n",
    "y_mppx = (y_mppx1 + y_mppx2) / 2\n",
    "\n",
    "print('Average meter/px along x-axis: {:.4f}'.format(x_mppx))\n",
    "print('Average meter/px along y-axis: {:.4f}'.format(y_mppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_offset_from_center(poly_param, x_mppx):\n",
    "    '''\n",
    "    Computes the offset of the car from the center of the detected lane lines\n",
    "    :param poly_param (ndarray): Set of 2nd order polynomial coefficients that represent the detected lane lines\n",
    "    :param x_mppx (float32): metres/pixel in the x-direction\n",
    "    :return (float32): Offset \n",
    "    '''\n",
    "    plot_xleft, plot_yleft, plot_xright, plot_yright = get_poly_points(poly_param[0], poly_param[1])\n",
    "    \n",
    "    lane_center = (plot_xright[-1] + plot_xleft[-1]) / 2\n",
    "    car_center = IMG_SHAPE[1] / 2\n",
    "    \n",
    "    offset = (lane_center - car_center) * x_mppx\n",
    "    return offset\n",
    "\n",
    "def compute_curvature(poly_param, y_mppx, x_mppx):\n",
    "    '''\n",
    "    Computes the curvature of the lane lines (in metres)\n",
    "    :param poly_param (ndarray): Set of 2nd order polynomial coefficients that represent the detected lane lines\n",
    "    :param y_mppx (float32): metres/pixel in the y-direction\n",
    "    :param x_mppx (float32): metres/pixel in the x-direction\n",
    "    :return (float32): Curvature (in metres) \n",
    "    '''\n",
    "    plot_xleft, plot_yleft, plot_xright, plot_yright = get_poly_points(poly_param[0], poly_param[1])\n",
    "    \n",
    "    y_eval = np.max(plot_yleft)\n",
    "\n",
    "    left_fit_cr = np.polyfit(plot_yleft * y_mppx, plot_xleft * x_mppx, 2)\n",
    "    right_fit_cr = np.polyfit(plot_yright * y_mppx, plot_xright * x_mppx, 2)\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]* y_eval*y_mppx + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*y_mppx + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def draw(img, warped, invM, poly_param, curve_rad, offset):\n",
    "    '''\n",
    "    Utility function to draw the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "    :param img (ndarray): Original image\n",
    "    :param warped (ndarray): Warped image\n",
    "    :param invM (ndarray): Inverse Perpsective Transformation matrix\n",
    "    :param poly_param (ndarray): Set of 2nd order polynomial coefficients that represent the detected lane lines\n",
    "    :param curve_rad (float32): Lane line curvature\n",
    "    :param offset (float32): Car offset\n",
    "    :return (ndarray): Image with visual display\n",
    "    '''\n",
    "    \n",
    "    undist = undistort(img, mtx, dist)\n",
    "    warp_zero = np.zeros_like(warped[:,:,0]).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    left_fit = poly_param[0]\n",
    "    right_fit = poly_param[1]\n",
    "    plot_xleft, plot_yleft, plot_xright, plot_yright = get_poly_points(left_fit, right_fit)\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([plot_xleft, plot_yleft]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([plot_xright, plot_yright])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Color the road\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 220, 110))\n",
    "                    \n",
    "    cv2.polylines(color_warp, np.int32([pts_left]), isClosed=False,\n",
    "                  color=(255, 255, 255), thickness=10)\n",
    "    cv2.polylines(color_warp, np.int32([pts_right]), isClosed=False,\n",
    "                  color=(255, 255, 255), thickness= 10)\n",
    "    \n",
    "    # Unwarp and merge with undistorted original image\n",
    "    unwarped = cv2.warpPerspective(color_warp, invM, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    out = cv2.addWeighted(undist, 1, unwarped, 0.4, 0)\n",
    "    \n",
    "    # Write data on the image\n",
    "    if (left_fit[1] + right_fit[1]) / 2 > 0.05:\n",
    "        text = 'Left turn, curve radius: {:04.2f} m'.format(curve_rad)\n",
    "    elif (left_fit[1] + right_fit[1]) / 2 < -0.05:\n",
    "        text = 'Right turn, curve radius: {:04.2f} m'.format(curve_rad)\n",
    "    else:\n",
    "        text = 'Straight'\n",
    "    \n",
    "    cv2.putText(out, text, (50, 60), cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    direction = ''\n",
    "    if offset > 0:\n",
    "        direction = 'left'\n",
    "    elif offset < 0:\n",
    "        direction = 'right'\n",
    "    \n",
    "    text = '{:0.1f} cm {} of center'.format(abs(offset) * 100, direction)\n",
    "    cv2.putText(out, text, (50, 110), cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 7 in plot_demo:\n",
    "    cache = np.array([])\n",
    "    \n",
    "    for img_path in test_img_paths:#test_img_paths:\n",
    "        img = mpimg.imread(img_path)\n",
    "        warped, (M, invM) = get_image(img_path)\n",
    "        \n",
    "        binary = get_binary_image(warped)\n",
    "        ret, img_poly, poly_param = polyfit_sliding_window(binary)\n",
    "        \n",
    "        left_curverad, right_curverad = compute_curvature(poly_param, y_mppx, x_mppx)\n",
    "        curvature = (left_curverad + right_curverad) / 2\n",
    "        offset = compute_offset_from_center(poly_param, x_mppx)\n",
    "        result = draw(img, warped, invM, poly_param, curvature, offset)\n",
    "        \n",
    "        plot_images([(img_poly, 'Polyfit'), (result, 'Result')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_split_view(images):\n",
    "    '''\n",
    "    Utility function to create triple split view for display in video\n",
    "    :param images ([ndarray]): List of images\n",
    "    :returm (ndarray): Single RGB image \n",
    "    '''\n",
    "\n",
    "    scale_factor = 2\n",
    "    \n",
    "    # Sizes/shapes are in (x,y) format for convenience use with cv2\n",
    "    img_shape = IMG_SHAPE[::-1]\n",
    "    scaled_size = (round(img_shape[0] / scale_factor), round(img_shape[1] / scale_factor))\n",
    "    x_max, y_max = img_shape[0], img_shape[1] + scaled_size[1] # x, y + y'\n",
    "\n",
    "    # Top-left corner positions for each of the three windows\n",
    "    positions = [(0,0), (0, img_shape[1]), (round(0.5 * img_shape[0]), img_shape[1])]\n",
    "    sizes = [img_shape, scaled_size, scaled_size] \n",
    "    \n",
    "    out = np.zeros((y_max, x_max, 3), dtype=np.uint8)\n",
    "\n",
    "    for idx, img in enumerate(images):\n",
    "        # Resize the image\n",
    "        if img.shape[0] != sizes[idx][1] | img.shape[1] != sizes[idx][0]:\n",
    "            img = cv2.resize(img, dsize=sizes[idx])\n",
    "\n",
    "        # Place the resized image onto the final output image\n",
    "        x, y = positions[idx]\n",
    "        w, h = sizes[idx]\n",
    "        out[y:min(y + h, y_max), x:min(x + w, x_max), :] = img[:min(h, y_max - y), :min(w, x_max - x)]\n",
    "\n",
    "    return out\n",
    "\n",
    "def pipeline(img, visualise=False, diagnostics=False):\n",
    "    global cache\n",
    "    global poly_param # Important for successive calls to the pipeline\n",
    "    global attempts\n",
    "    global reset\n",
    "    max_attempts = 5\n",
    "    \n",
    "    result = np.copy(img)\n",
    "    warped, (M, invM) = preprocess_image(img)\n",
    "    title = ''\n",
    "   \n",
    "    try:\n",
    "        if reset == True:\n",
    "            title = 'Sliding window'\n",
    "            if diagnostics: print(title)\n",
    "            \n",
    "            binary = get_binary_image(warped)\n",
    "            ret, img_poly, poly_param = polyfit_sliding_window(binary, diagnostics=diagnostics)\n",
    "            if ret:\n",
    "                if diagnostics: print('Success!')\n",
    "                reset = False\n",
    "                cache = np.array([poly_param])\n",
    "            else:\n",
    "                if len(img_poly) == 0:\n",
    "                    print('Sliding window failed!')\n",
    "                    return img\n",
    "                \n",
    "        else:\n",
    "            title = 'Adaptive Search'\n",
    "            if diagnostics: print(title)\n",
    "            \n",
    "            img_poly, poly_param = polyfit_adapt_search(warped, poly_param, diagnostics=diagnostics)\n",
    "            if attempts == max_attempts:\n",
    "                if diagnostics: print('Resetting...')\n",
    "                reset = True\n",
    "                attempts = 0\n",
    "        \n",
    "        left_curverad, right_curverad = compute_curvature(poly_param, y_mppx, x_mppx)\n",
    "        offset = compute_offset_from_center(poly_param, x_mppx)\n",
    "        result = draw(img, warped, invM, poly_param, (left_curverad + right_curverad) / 2, offset)\n",
    "\n",
    "        blended_warped_poly = cv2.addWeighted(img_poly, 0.6, warped, 1, 0)\n",
    "        ret2 = np.hstack([img_poly, blended_warped_poly])\n",
    "        ret3 = np.hstack([result, warped])\n",
    "#         ret3 = triple_split_view([result, img_poly, blended_warped_poly])\n",
    "        ret3 = np.vstack([ret3, ret2])\n",
    "        if visualise:\n",
    "            plt.figure(figsize=(20, 12))\n",
    "            plt.title(title)\n",
    "            plt.imshow(ret3)\n",
    "\n",
    "        return ret3\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 8 in plot_demo:\n",
    "    print('Demo of consecutive frames')\n",
    "    \n",
    "    cache = np.array([])\n",
    "    attempts = 0\n",
    "    reset = True\n",
    "    \n",
    "    for img_path in test_img_paths[0:1]:\n",
    "        img = mpimg.imread(img_path)\n",
    "        result = pipeline(img, visualise=True, diagnostics=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "process_frame = lambda frame: pipeline(frame, diagnostics=1)\n",
    "\n",
    "# Pipeline initialisation\n",
    "cache = np.array([])\n",
    "attempts = 0\n",
    "reset = True\n",
    "\n",
    "#video_output = 'project_video_output.mp4'\n",
    "#video_input = VideoFileClip('project_video.mp4')#.subclip(18,27)\n",
    "#video_input.close()\n",
    "#processed_video = video_input.fl_image(process_frame)\n",
    "#%time processed_video.write_videofile(video_output, audio=False)\n",
    "\n",
    "\n",
    "video1_output = 'challenge_video_output2.mp4'\n",
    "video1_input = VideoFileClip('prank.mp4')#.subclip(4, 7)                          \n",
    "processed_video = video1_input.fl_image(process_frame)\n",
    "%time processed_video.write_videofile(video1_output, audio=False)\n",
    "\n",
    "# video2_output = 'harder_challenge_video_output.mp4'\n",
    "# video2_input = VideoFileClip('harder_challenge_video.mp4')                          \n",
    "# processed_video = video2_input.fl_image(process_frame)#.subclip(0,5)\n",
    "# %time processed_video.write_videofile(video2_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
